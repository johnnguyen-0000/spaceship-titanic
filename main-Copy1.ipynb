{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: \n",
    "\n",
    "First we import some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: \n",
    "\n",
    "loading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitanic_test_file_path = 'test.csv'\n",
    "stitanic_train_file_path = 'train.csv'\n",
    "\n",
    "stitanic_data = pd.read_csv(stitanic_train_file_path)\n",
    "df_test = pd.read_csv(stitanic_test_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3:\n",
    "\n",
    "***Cleaning and exploring the data***\n",
    "\n",
    "Note:\n",
    "- When we copy one columns in Pandas, we also copy the missing value(NaN)\n",
    "- So we need to fill the missing value before copy a collumn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***For Homeplanet***\n",
    "\n",
    "- First, we will clean the data in Homplanet collumns.The function ***stitanic_data[\"HomePlanet\"].value_counts()***  returns object containing counts of unique values \n",
    "\n",
    "HomePlanet    \n",
    "Earth     4602  \n",
    "Europa    2131\n",
    "Mars      1759      \n",
    "Name: count, dtype: int64\n",
    "  \n",
    "  \n",
    "- After that, we will fill the collumn HomePlanet with the number occurs most often  \n",
    "- Then, by using the function .get_dummies() , we will create new categorical columns : Earth, Europa and Mars  \n",
    "For example :\n",
    "  \n",
    "   Homeplanet                                      \n",
    "1 &emsp;    Earth                                        \n",
    "2 &emsp;    Mars                 \n",
    "3  &emsp;   Europa                                       \n",
    "4   &emsp;  Mars                                         \n",
    "will become \n",
    "\n",
    "&emsp;&nbsp; Earth &emsp; Mars &emsp; Europa    \n",
    "1  &nbsp;1.00 &emsp;&nbsp; 0.00 &emsp;&nbsp; 0.00   \n",
    "2  &nbsp;0.00 &emsp;&nbsp; 1.00 &emsp;&nbsp; 0.00   \n",
    "3  &nbsp;0.00 &emsp;&nbsp; 0.00 &emsp;&nbsp; 1.00   \n",
    "4  &nbsp;0.00 &emsp;&nbsp; 1.00 &emsp;&nbsp; 0.00   \n",
    "- Finally we will drop the unecessary column : HomePlanet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitanic_data['HomePlanet'] = stitanic_data['HomePlanet'].fillna(\"Earth\")\n",
    "stitanic_homeplanet = pd.get_dummies(stitanic_data['HomePlanet'] , dtype = float)\n",
    "stitanic_data = pd.concat([stitanic_data , stitanic_homeplanet ] ,axis = 1)\n",
    "del stitanic_data[\"HomePlanet\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do the same with the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['HomePlanet'] = df_test['HomePlanet'].fillna(\"Earth\")\n",
    "df_homeplanet = pd.get_dummies(df_test['HomePlanet'] , dtype = float)\n",
    "df_test = pd.concat([df_test , df_homeplanet] ,axis = 1) \n",
    "del df_test['HomePlanet'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***For CryoSleep***  \n",
    "We do the same thing with CryoSleep ***stitanic_data['CryoSleep'].value_counts()***  \n",
    "Result: number of zero >number of 1 so we replace NaN = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitanic_data['CryoSleep'] = stitanic_data['CryoSleep'].fillna(0)\n",
    "stitanic_data['CryoSleep'] = stitanic_data['CryoSleep'].replace([False,True],[ 0 , 1 ])\n",
    "\n",
    "df_test['CryoSleep'] = df_test['CryoSleep'].fillna(0)\n",
    "df_test['CryoSleep'] = df_test['CryoSleep'].replace([False,True],[ 0 , 1 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***For Cabin***  \n",
    "We have to split the type of Cabin from Deck/Num/side to column Deck , Num , side seperately.   \n",
    "Because Cabin data are string data type so we can use string slicing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitanic_data['C_Deck'] = stitanic_data['Cabin'].str[0] \n",
    "stitanic_data['C_Num'] = stitanic_data['Cabin'].str[2 : -2]\n",
    "stitanic_data['C_Side'] = stitanic_data['Cabin'].str[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I don't know how to do yet.  \n",
    "***For C_Num we have to change the dtype from object to categorical to use in the XGB model.***  \n",
    "The two column C_Deck and C_side we do the same thing as ***Homeplanet*** column. \n",
    "We have to fill NaN in  C_Num, C_Deck, C_Side with mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitanic_data['C_Deck'] = stitanic_data['C_Deck'].fillna(\"F\") \n",
    "stitanic_data['C_Num'] = stitanic_data['C_Num'].fillna(stitanic_data['C_Num'].mode()[0]) # fill with median or số xuất hiện nhiều nhất\n",
    "stitanic_data['C_Side'] = stitanic_data['C_Side'].fillna(\"S\")\n",
    "\n",
    "stitanic_deck = pd.get_dummies(stitanic_data['C_Deck'], prefix = \"C_Deck\" , dtype = float)\n",
    "stitanic_data = pd.concat([stitanic_data , stitanic_deck ] ,axis = 1)\n",
    "\n",
    "stitanic_side = pd.get_dummies(stitanic_data['C_Side'], prefix = \"C_Side\" , dtype = float)\n",
    "stitanic_data = pd.concat([stitanic_data , stitanic_side] ,axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally is dropping column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del stitanic_data['Cabin']\n",
    "del stitanic_data['C_Deck']\n",
    "del stitanic_data['C_Side']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "#split -> deck , num , side \n",
    "df_test['C_Deck'] = df_test['Cabin'].str[0] \n",
    "df_test['C_Num'] = df_test['Cabin'].str[2 : -2]\n",
    "df_test['C_Side'] = df_test['Cabin'].str[-1]\n",
    "\n",
    "#đổi C_num từ dtype object sang float \n",
    "#fill\n",
    "# F G  E  B  C  D  A  T\n",
    "#print(df_test['C_Deck'].value_counts())\n",
    "#fill\n",
    "\n",
    "df_test['C_Deck'] = df_test['C_Deck'].fillna(\"F\")\n",
    "df_test['C_Num'] = df_test['C_Num'].fillna(df_test['C_Num'].mode()[0]) # fill with median or mode vì cnum ko phải là int\n",
    "df_test['C_Side'] = df_test['C_Side'].fillna(\"S\") # fill S hay random vì S 2093 P 2084\n",
    "\n",
    "#\n",
    "df_deck = pd.get_dummies(df_test['C_Deck'], prefix = \"C_Deck\", dtype = float)\n",
    "df_test = pd.concat([df_test , df_deck],axis = 1) \n",
    " \n",
    "df_side = pd.get_dummies(df_test['C_Side'], prefix = \"C_Side\", dtype = float) # có nên để trong 1 cột ko ?\n",
    "df_test = pd.concat([df_test , df_side],axis = 1) \n",
    "\n",
    "#drop col\n",
    "del df_test['Cabin']\n",
    "del df_test['C_Deck']\n",
    "del df_test['C_Side']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***For Destination***\n",
    "It is similar to HomePlanet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitanic_data['Destination'] = stitanic_data['Destination'].fillna('TRAPPIST-1e')\n",
    "stitanic_destination = pd.get_dummies(stitanic_data['Destination'], dtype = float)\n",
    "stitanic_data = pd.concat([stitanic_data ,stitanic_destination ],axis = 1) \n",
    "del stitanic_data['Destination']\n",
    "\n",
    "#test\n",
    "df_test['Destination'] = df_test['Destination'].fillna('TRAPPIST-1e')\n",
    "df_destination = pd.get_dummies(df_test['Destination'], dtype = float)\n",
    "df_test = pd.concat([df_test , df_destination],axis = 1) \n",
    "del df_test['Destination']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***For Ag, RoomService, FoodCourt, ShoppingMall, Spa, and VRDeck***  \n",
    "We just simply replace the NaN value by the columns median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitanic_data['Age'] = stitanic_data['Age'].fillna(stitanic_data['Age'].median())\n",
    "df_test['Age'] = df_test['Age'].fillna(df_test['Age'].median())\n",
    "\n",
    "#Vip\n",
    "#class bool\n",
    "#stitanic_data['VIP'].value_counts()\n",
    "#print( stitanic_data['VIP'].value_counts())  false > true \n",
    "stitanic_data['VIP'] = stitanic_data['VIP'].fillna(0)\n",
    "stitanic_data['VIP'] = stitanic_data['VIP'].replace([False,True],[ 0 , 1 ])\n",
    "df_test['VIP'] = df_test['VIP'].fillna(0)\n",
    "df_test['VIP'] = df_test['VIP'].replace([False,True],[ 0 , 1 ])\n",
    "\n",
    "\n",
    "#RoomService \n",
    "#class int\n",
    "stitanic_data['RoomService'] = stitanic_data['RoomService'].fillna(stitanic_data['RoomService'].median())\n",
    "df_test['RoomService'] = df_test['RoomService'].fillna(df_test['RoomService'].median())\n",
    "\n",
    "#FoodCourt\n",
    "#class int\n",
    "stitanic_data['FoodCourt'] = stitanic_data['FoodCourt'].fillna(stitanic_data['FoodCourt'].median())\n",
    "df_test['FoodCourt'] = df_test['FoodCourt'].fillna(df_test['FoodCourt'].median())\n",
    "\n",
    "#ShoppingMall\n",
    "#class int\n",
    "stitanic_data['ShoppingMall'] = stitanic_data['ShoppingMall'].fillna(stitanic_data['ShoppingMall'].median())\n",
    "df_test['ShoppingMall'] = df_test['ShoppingMall'].fillna (df_test['ShoppingMall'].median())\n",
    "\n",
    "#Spa\n",
    "#class int\n",
    "stitanic_data['Spa'] = stitanic_data['Spa'].fillna(stitanic_data['Spa'].median())\n",
    "df_test['Spa'] = df_test['Spa'].fillna( df_test['Spa'].median() )\n",
    "\n",
    "#VRDeck\n",
    "\n",
    "stitanic_data['VRDeck'] = stitanic_data['VRDeck'].fillna(stitanic_data['VRDeck'].median())\n",
    "df_test['VRDeck'] = df_test['VRDeck'].fillna( df_test['VRDeck'].median() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***For Name*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del stitanic_data[\"Name\"]\n",
    "del df_test['Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Plotting variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***1. correlation analysis***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitanic_cor = stitanic_data.corr(method='pearson')\n",
    "#sns.barplot(x=stitanic_cor['Transported'] , y= stitanic_cor.columns)\n",
    "\n",
    "#heatmap but it cannot show columns so I use barchart\n",
    "stitanc_cor_trans = stitanic_cor['Transported'].values.reshape(27,1)\n",
    "plt.figure(figsize=(len (stitanic_data.columns) , len (stitanic_data.columns) ))\n",
    "plt.title(\"correlation analysis\")\n",
    "sns.heatmap(data = stitanc_cor_trans , annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***2. FoodCourt***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "sns.lineplot(data=stitanic_data['FoodCourt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***3. Age***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x= len(stitanic_data['Age'], y=stitanic_data['Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, We will use the ***accuracy_score*** to validate the model and splitting the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#split data into train and test (8:2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "stitanic_base =  [ item for item in stitanic_data.columns if item != 'Transported' ]\n",
    "X = stitanic_data[stitanic_base] \n",
    "y = stitanic_data['Transported']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2 , random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, I will try 3 model ,decision tree , logistic regerssion, and xgboost, to see which one is the best "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - The first one is logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_logistic = LogisticRegression()\n",
    "model_logistic.fit(X_train, y_train)\n",
    "predict_log_train = model_logistic.predict(X_train)\n",
    "predict_log_test = model_logistic.predict(X_test) \n",
    "predict_log_ans = model_logistic.predict(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to validate the model by creating a small test set from the training set.  \n",
    "Then, we print the result out to select the best model  \n",
    "We will choose the model with highest performance in the test_log_pt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log_pt = accuracy_score (predict_log_train , y_train )\n",
    "test_log_pt = accuracy_score (predict_log_test , y_test )\n",
    "print ( train_log_pt, test_log_pt , sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - The second one is decision tree   \n",
    "  &emsp; We need to choose the max_depth of a decision tree  \n",
    "  &emsp; The max_depth = 5 return the best result   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_tree = DecisionTreeClassifier( max_depth = 5, random_state = 1)\n",
    "model_tree.fit(X_train , y_train)\n",
    "predict_tree_train = model_tree.predict(X_train)\n",
    "predict_tree_test= model_tree.predict(X_test)\n",
    "predict_tree_ans = model_tree.predict(df_test)\n",
    "train_tree_pt = accuracy_score(predict_tree_train , y_train)\n",
    "test_tree_pt = accuracy_score(predict_tree_test , y_test)\n",
    "print ( train_tree_pt , test_tree_pt , sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - The third one is xgboost  \n",
    "    &emsp; We need to use ._get_numeric_data() to fit the xgboost, this will drop the C_Num and PassengerId columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model_xgb = XGBClassifier()\n",
    "#xgb ko nhận được dtype :object nên phải dùng ._get_numeric_data()\n",
    "#nó sẽ drop C_num và passengerId\n",
    "model_xgb.fit(X_train._get_numeric_data() , y_train)\n",
    "predict_xgb_train = model_xgb.predict(X_train._get_numeric_data())\n",
    "predict_xgb_test= model_xgb.predict(X_test._get_numeric_data())\n",
    "predict_xgb_ans = model_xgb.predict(df_test._get_numeric_data())\n",
    "train_xgb_pt = accuracy_score(predict_xgb_train , y_train)\n",
    "test_xgb_pt = accuracy_score(predict_xgb_test , y_test)\n",
    "#print ( train_xgb_pt , test_xgb_pt , sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 : Submission\n",
    "\n",
    " &emsp; The second line is for xgb because it automatically converted the Transported column into 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"Transported\"] = predict_log_ans\n",
    "#df_test[\"Transported\"] = df_test[\"Transported\"].replace([0,1],[ False, True ])\n",
    "csv = df_test[['PassengerId',\"Transported\"]]\n",
    "\n",
    "csv.to_csv(\"sub_stitanic_logistic_2.csv\", index = False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HomePlanet\n",
      "Earth     4602\n",
      "Europa    2131\n",
      "Mars      1759\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#submission xgb\\ndf_test[\"Transported\"] = predict_ans\\n#df_test[\"Transported\"] = df_test[\"Transported\"].replace([0,1],[ False, True ])\\ncsv = df_test[[\\'PassengerId\\',\"Transported\"]]\\n\\ncsv.to_csv(\"sub_stitanic_logistic_2.csv\", index = False)\\n'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Some useful command\n",
    "\n",
    "#predict_ans = model_logistic.predict(df_test)\n",
    "#print(predict_ans)\n",
    "\n",
    "#print(stitanic_data)\n",
    "#missing_cnt = df_test.isnull().sum()\n",
    "\n",
    "#print(stitanic_data['Transported'].head())\n",
    "\n",
    "#print(missing_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
