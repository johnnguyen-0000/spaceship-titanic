{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PassengerId  CryoSleep   Age  VIP  RoomService  FoodCourt  ShoppingMall  \\\n",
      "0     0001_01          0  39.0    0          0.0        0.0           0.0   \n",
      "1     0002_01          0  24.0    0        109.0        9.0          25.0   \n",
      "2     0003_01          0  58.0    1         43.0     3576.0           0.0   \n",
      "3     0003_02          0  33.0    0          0.0     1283.0         371.0   \n",
      "4     0004_01          0  16.0    0        303.0       70.0         151.0   \n",
      "\n",
      "      Spa  VRDeck  Transported  ...  C_Deck_D  C_Deck_E  C_Deck_F C_Deck_G  \\\n",
      "0     0.0     0.0            0  ...       0.0       0.0       0.0      0.0   \n",
      "1   549.0    44.0            1  ...       0.0       0.0       1.0      0.0   \n",
      "2  6715.0    49.0            0  ...       0.0       0.0       0.0      0.0   \n",
      "3  3329.0   193.0            0  ...       0.0       0.0       0.0      0.0   \n",
      "4   565.0     2.0            1  ...       0.0       0.0       1.0      0.0   \n",
      "\n",
      "   C_Deck_T  C_Side_P  C_Side_S  55 Cancri e  PSO J318.5-22  TRAPPIST-1e  \n",
      "0       0.0       1.0       0.0          0.0            0.0          1.0  \n",
      "1       0.0       0.0       1.0          0.0            0.0          1.0  \n",
      "2       0.0       0.0       1.0          0.0            0.0          1.0  \n",
      "3       0.0       0.0       1.0          0.0            0.0          1.0  \n",
      "4       0.0       0.0       1.0          0.0            0.0          1.0  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "  PassengerId  CryoSleep   Age  VIP  RoomService  FoodCourt  ShoppingMall  \\\n",
      "0     0013_01          1  27.0    0          0.0        0.0           0.0   \n",
      "1     0018_01          0  19.0    0          0.0        9.0           0.0   \n",
      "2     0019_01          1  31.0    0          0.0        0.0           0.0   \n",
      "3     0021_01          0  38.0    0          0.0     6652.0           0.0   \n",
      "4     0023_01          0  20.0    0         10.0        0.0         635.0   \n",
      "\n",
      "      Spa  VRDeck  Earth  ...  C_Deck_D  C_Deck_E C_Deck_F  C_Deck_G  \\\n",
      "0     0.0     0.0    1.0  ...       0.0       0.0      0.0       1.0   \n",
      "1  2823.0     0.0    1.0  ...       0.0       0.0      1.0       0.0   \n",
      "2     0.0     0.0    0.0  ...       0.0       0.0      0.0       0.0   \n",
      "3   181.0   585.0    0.0  ...       0.0       0.0      0.0       0.0   \n",
      "4     0.0     0.0    1.0  ...       0.0       0.0      1.0       0.0   \n",
      "\n",
      "   C_Deck_T  C_Side_P  C_Side_S  55 Cancri e  PSO J318.5-22  TRAPPIST-1e  \n",
      "0       0.0       0.0       1.0          0.0            0.0          1.0  \n",
      "1       0.0       0.0       1.0          0.0            0.0          1.0  \n",
      "2       0.0       0.0       1.0          1.0            0.0          0.0  \n",
      "3       0.0       0.0       1.0          0.0            0.0          1.0  \n",
      "4       0.0       0.0       1.0          0.0            0.0          1.0  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "#import sklearn \n",
    "import seaborn as sns\n",
    "import scipy \n",
    "import numpy as np\n",
    "\n",
    "#load data \n",
    "stitanic_test_file_path = 'test.csv'\n",
    "stitanic_train_file_path = 'train.csv'\n",
    "\n",
    "stitanic_data = pd.read_csv(stitanic_train_file_path)\n",
    "df_test = pd.read_csv(stitanic_test_file_path)\n",
    "\n",
    "\n",
    "#clean and explore data\n",
    "\n",
    "\n",
    "# Home planet\n",
    "#class str\n",
    "#check gt lớn nhất \n",
    "#print(stitanic_data['HomePlanet'].value_counts()) : Earth là nhiều nhất \n",
    "#fill\n",
    "#create new col\n",
    "#drop oldcol\n",
    "\n",
    "stitanic_data['HomePlanet'] = stitanic_data['HomePlanet'].fillna(\"Earth\")\n",
    "stitanic_homeplanet = pd.get_dummies(stitanic_data['HomePlanet'] , dtype = float)\n",
    "stitanic_data = pd.concat([stitanic_data , stitanic_homeplanet ] ,axis = 1)\n",
    "del stitanic_data[\"HomePlanet\"]\n",
    "\n",
    "#test\n",
    "df_test['HomePlanet'] = df_test['HomePlanet'].fillna(\"Earth\")\n",
    "df_homeplanet = pd.get_dummies(df_test['HomePlanet'] , dtype = float)\n",
    "df_test = pd.concat([df_test , df_homeplanet] ,axis = 1) \n",
    "del df_test['HomePlanet'] \n",
    "\n",
    "\n",
    "#stitanic_data = pd.concat([stitanic_data, pd.get_dummies(stitanic_data['HomePlanet'] , dtype = float) ], axis=1 )\n",
    "\n",
    "#cryosleep\n",
    "#class bool \n",
    "#check the quantity of 0 and 1\n",
    "#stitanic_data['CryoSleep'].value_counts()\n",
    "# number of zero >number of 1\n",
    "#replace  nan = 0 \n",
    "stitanic_data['CryoSleep'] = stitanic_data['CryoSleep'].fillna(0)\n",
    "stitanic_data['CryoSleep'] = stitanic_data['CryoSleep'].replace([False,True],[ 0 , 1 ])\n",
    "#test\n",
    "df_test['CryoSleep'] = df_test['CryoSleep'].fillna(0)\n",
    "df_test['CryoSleep'] = df_test['CryoSleep'].replace([False,True],[ 0 , 1 ])\n",
    "\n",
    "\n",
    "\n",
    "#Cabin\n",
    "# split cabin -> deck  , num , side\n",
    "\n",
    "stitanic_data['C_Deck'] = stitanic_data['Cabin'].str[0] \n",
    "stitanic_data['C_Num'] = stitanic_data['Cabin'].str[2 : -2]\n",
    "stitanic_data['C_Side'] = stitanic_data['Cabin'].str[-1]\n",
    "\n",
    "#drop cabin\n",
    "#del stitanic_data['Cabin'] \n",
    "#check gt lon nhat F G E B C D A T \n",
    "#print(stitanic_data['C_Deck'].value_counts())\n",
    "#check gt lon nhat  S : 4288 P :4206\n",
    "#print(stitanic_data['C_Side'].value_counts()) \n",
    "\n",
    "#fill num\n",
    "stitanic_data['C_Deck'] = stitanic_data['C_Deck'].fillna(\"F\")\n",
    "stitanic_data['C_Num'] = stitanic_data['C_Num'].fillna(stitanic_data['C_Num'].median()) # fill with median or số xuất hiện nhiều nhất\n",
    "stitanic_data['C_Side'] = stitanic_data['C_Side'].fillna(\"S\")\n",
    "#new col deck_f\n",
    "\n",
    "stitanic_deck = pd.get_dummies(stitanic_data['C_Deck'], prefix = \"C_Deck\" , dtype = float)\n",
    "stitanic_data = pd.concat([stitanic_data , stitanic_deck ] ,axis = 1)\n",
    "\n",
    "stitanic_side = pd.get_dummies(stitanic_data['C_Side'], prefix = \"C_Side\" , dtype = float)\n",
    "stitanic_data = pd.concat([stitanic_data , stitanic_side] ,axis = 1)\n",
    "\n",
    "#drop col\n",
    "del stitanic_data['Cabin']\n",
    "del stitanic_data['C_Deck']\n",
    "del stitanic_data['C_Side']\n",
    "\n",
    "#test\n",
    "#split -> deck , num , side \n",
    "df_test['C_Deck'] = df_test['Cabin'].str[0] \n",
    "df_test['C_Num'] = df_test['Cabin'].str[2 : -2]\n",
    "df_test['C_Side'] = df_test['Cabin'].str[-1]\n",
    "\n",
    "#fill\n",
    "# F G  E  B  C  D  A  T\n",
    "#print(df_test['C_Deck'].value_counts())\n",
    "\n",
    "#fill\n",
    "df_test['C_Deck'] = df_test['C_Deck'].fillna(\"F\")\n",
    "df_test['C_Num'] = df_test['C_Num'].fillna(df_test['C_Num'].median()) # fill with median or số xuất hiện nhiều nhất\n",
    "df_test['C_Side'] = df_test['C_Side'].fillna(\"S\") # fill S hay random vì S 2093 P 2084\n",
    "\n",
    "#\n",
    "df_deck = pd.get_dummies(df_test['C_Deck'], prefix = \"C_Deck\", dtype = float)\n",
    "df_test = pd.concat([df_test , df_deck],axis = 1) \n",
    " \n",
    "df_side = pd.get_dummies(df_test['C_Side'], prefix = \"C_Side\", dtype = float) # có nên để trong 1 cột ko ?\n",
    "df_test = pd.concat([df_test , df_side],axis = 1) \n",
    "\n",
    "#drop col\n",
    "del df_test['Cabin']\n",
    "del df_test['C_Deck']\n",
    "del df_test['C_Side']\n",
    "\n",
    "\n",
    "#Destination\n",
    "#class str \n",
    "#check gt lon nhat \n",
    "#print(stitanic_data['Destination'].value_counts()) TRAPPIST-1e\n",
    "#fill\n",
    "#newcol\n",
    "#drop oldcol\n",
    "\n",
    "stitanic_data['Destination'] = stitanic_data['Destination'].fillna('TRAPPIST-1e')\n",
    "stitanic_destination = pd.get_dummies(stitanic_data['Destination'], dtype = float)\n",
    "stitanic_data = pd.concat([stitanic_data ,stitanic_destination ],axis = 1) \n",
    "del stitanic_data['Destination']\n",
    "\n",
    "#test\n",
    "df_test['Destination'] = df_test['Destination'].fillna('TRAPPIST-1e')\n",
    "df_destination = pd.get_dummies(df_test['Destination'], dtype = float)\n",
    "df_test = pd.concat([df_test , df_destination],axis = 1) \n",
    "del df_test['Destination']\n",
    "\n",
    "#Age\n",
    "#class int\n",
    "stitanic_data['Age'] = stitanic_data['Age'].fillna(stitanic_data['Age'].median())\n",
    "df_test['Age'] = df_test['Age'].fillna(df_test['Age'].median())\n",
    "\n",
    "#Vip\n",
    "#class bool\n",
    "#stitanic_data['VIP'].value_counts()\n",
    "#print( stitanic_data['VIP'].value_counts())  false > true \n",
    "stitanic_data['VIP'] = stitanic_data['VIP'].fillna(0)\n",
    "stitanic_data['VIP'] = stitanic_data['VIP'].replace([False,True],[ 0 , 1 ])\n",
    "df_test['VIP'] = df_test['VIP'].fillna(0)\n",
    "df_test['VIP'] = df_test['VIP'].replace([False,True],[ 0 , 1 ])\n",
    "\n",
    "\n",
    "#RoomService \n",
    "#class int\n",
    "stitanic_data['RoomService'] = stitanic_data['RoomService'].fillna(stitanic_data['RoomService'].median())\n",
    "df_test['RoomService'] = df_test['RoomService'].fillna(df_test['RoomService'].median())\n",
    "\n",
    "#FoodCourt\n",
    "#class int\n",
    "stitanic_data['FoodCourt'] = stitanic_data['FoodCourt'].fillna(stitanic_data['FoodCourt'].median())\n",
    "df_test['FoodCourt'] = df_test['FoodCourt'].fillna(df_test['FoodCourt'].median())\n",
    "\n",
    "#ShoppingMall\n",
    "#class int\n",
    "stitanic_data['ShoppingMall'] = stitanic_data['ShoppingMall'].fillna(stitanic_data['ShoppingMall'].median())\n",
    "df_test['ShoppingMall'] = df_test['ShoppingMall'].fillna (df_test['ShoppingMall'].median())\n",
    "\n",
    "#Spa\n",
    "#class int\n",
    "stitanic_data['Spa'] = stitanic_data['Spa'].fillna(stitanic_data['Spa'].median())\n",
    "df_test['Spa'] = df_test['Spa'].fillna( df_test['Spa'].median() )\n",
    "\n",
    "#VRDeck\n",
    "\n",
    "stitanic_data['VRDeck'] = stitanic_data['VRDeck'].fillna(stitanic_data['VRDeck'].median())\n",
    "df_test['VRDeck'] = df_test['VRDeck'].fillna( df_test['VRDeck'].median() )\n",
    "\n",
    "#Name\n",
    "#drop\n",
    "del stitanic_data[\"Name\"]\n",
    "del df_test['Name']\n",
    "\n",
    "\n",
    "#Transported\n",
    "stitanic_data['Transported'] = stitanic_data['Transported'].replace([False,True],[ 0 , 1 ])\n",
    "\n",
    "\n",
    "#xem data có make sense ko\n",
    "#plot 3 variables\n",
    "\n",
    " \n",
    "#correlation analysis\n",
    "'''\n",
    "stitanic_cor = stitanic_data.corr(method='pearson')\n",
    "plt.figure(figsize=(len (stitanic_data.columns) ,len (stitanic_data.columns)))\n",
    "plt.title( \"correlation analysis\")\n",
    "sns.heatmap(data=stitanic_cor, annot=True)\n",
    "'''\n",
    "\n",
    "#count = 0 \n",
    "#stitanic_cor.columns :\n",
    "#for coll in stitanic_cor.columns :\n",
    "#    for row in stitanic_cor.columns : #range (len (stitanic_cor[coll]) ) :\n",
    "#       if stitanic_cor[coll][row] >= 0.3 and stitanic_cor[coll][row] != 1:\n",
    "#           count += 1\n",
    "#           print ( coll , row , sep = ' ')\n",
    "#           print ( \" - \" , str(stitanic_cor[coll][row]) , end = '\\n')\n",
    "    \n",
    "#print (\" count = \" , str(count) )\n",
    "\n",
    "\n",
    "#algorithm\n",
    "\n",
    "\n",
    "#metric accuracy\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "#split data into train and test (8:2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "stitanic_data_base =  [ item for item in stitanic_data.columns if item != 'Transported' and item != 'PassengerId']\n",
    "X = stitanic_data[stitanic_data_base] \n",
    "\n",
    "y = stitanic_data['Transported']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2 , random_state = 42)\n",
    "\n",
    "#logistic regression\n",
    "'''\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_logistic = LogisticRegression()\n",
    "model_logistic.fit(X_train, y_train)\n",
    "predict_log_train = model_logistic.predict(X_train)\n",
    "predict_log_test = model_logistic.predict(X_test) \n",
    "#predict_ans = model_logistic.predict(df_test)\n",
    "train_log_pt = accuracy_score (predict_log_train , y_train )\n",
    "test_log_pt = accuracy_score (predict_log_test , y_test )\n",
    "print ( train_log_pt, test_log_pt , sep = '\\n')\n",
    "'''\n",
    "\n",
    "# \n",
    "\n",
    "#decision tree \n",
    "'''\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_tree = DecisionTreeClassifier( max_depth = 5, random_state = 1)\n",
    "model_tree.fit(X_train , y_train)\n",
    "predict_tree_train = model_tree.predict(X_train)\n",
    "predict_tree_test= model_tree.predict(X_test)\n",
    "train_tree_pt = accuracy_score(predict_tree_train , y_train)\n",
    "test_tree_pt = accuracy_score(predict_tree_test , y_test)\n",
    "print ( train_tree_pt , test_tree_pt , sep = '\\n')\n",
    "'''\n",
    "\n",
    "#submission \n",
    "#choosing model \n",
    "\n",
    "#predict_ans = model_logistic.predict(df_test)\n",
    "#print(predict_ans)\n",
    "\n",
    "\n",
    "\n",
    "#missing_cnt = stitanic_data.isnull().sum()\n",
    "\n",
    "#print(stitanic_data['Transported'].head())\n",
    "#print (stitanic_data.describe()) \n",
    "#print(missing_cnt)\n",
    "print (stitanic_data.head())\n",
    "print (df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
